{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FWkuJabJSKGB"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Confirm that we're using Python 3\n",
    "assert sys.version_info.major is 3, 'Oops, not running Python 3. Use Runtime > Change runtime type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dzLKpmZICaWN",
    "outputId": "9930ff96-7033-48f1-f014-4483c8adac2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing dependencies for Colab environment\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "TensorFlow version: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "print(\"Installing dependencies for Colab environment\")\n",
    "!pip install -Uq grpcio==1.32.0\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "print('TensorFlow version: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7MqDQO0KCaWS",
    "outputId": "21c21532-7f58-47bd-fad8-7a3df0ae9be8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 3s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n",
      "\n",
      "train_images.shape: (60000, 28, 28, 1), of float64\n",
      "test_images.shape: (10000, 28, 28, 1), of float64\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# scale the values to 0.0 to 1.0\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# reshape for feeding into the model\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "print('\\ntrain_images.shape: {}, of {}'.format(train_images.shape, train_images.dtype))\n",
    "print('test_images.shape: {}, of {}'.format(test_images.shape, test_images.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LTNN0ANGgA36",
    "outputId": "f53437a9-12ea-45fd-ff4a-fdd4a92c5007"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv1 (Conv2D)               (None, 13, 13, 8)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1352)              0         \n",
      "_________________________________________________________________\n",
      "Softmax (Dense)              (None, 10)                13530     \n",
      "=================================================================\n",
      "Total params: 13,610\n",
      "Trainable params: 13,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7362 - accuracy: 0.7584\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3781 - accuracy: 0.8675\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3375 - accuracy: 0.8780\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3184 - accuracy: 0.8869\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3087 - accuracy: 0.8895\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3387 - accuracy: 0.8787\n",
      "\n",
      "Test accuracy: 0.8787000179290771\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "  keras.layers.Conv2D(input_shape=(28,28,1), filters=8, kernel_size=3, \n",
    "                      strides=2, activation='relu', name='Conv1'),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(10, activation=tf.nn.softmax, name='Softmax')\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "testing = False\n",
    "epochs = 5\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=epochs)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('\\nTest accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0w5Rq8SsgWE6",
    "outputId": "4ec23866-fee8-4522-9f8c-240e40069fe4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export_path = /tmp/1\n",
      "\n",
      "INFO:tensorflow:Assets written to: API/Fashion/1/assets\n",
      "\n",
      "Saved model:\n",
      "total 88\n",
      "drwxr-xr-x 2 root root  4096 Mar  3 22:19 assets\n",
      "-rw-r--r-- 1 root root 79036 Mar  3 22:19 saved_model.pb\n",
      "drwxr-xr-x 2 root root  4096 Mar  3 22:19 variables\n"
     ]
    }
   ],
   "source": [
    "# Fetch the Keras session and save the model\n",
    "# The signature definition is defined by the input and output tensors,\n",
    "# and stored with the default serving key\n",
    "import tempfile\n",
    "\n",
    "MODEL_DIR = tempfile.gettempdir()\n",
    "version = 1\n",
    "export_path = os.path.join(MODEL_DIR, str(version))\n",
    "print('export_path = {}\\n'.format(export_path))\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    \"API/Fashion/1\",\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None\n",
    ")\n",
    "\n",
    "print('\\nSaved model:')\n",
    "!ls -l {export_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "TYlTrmRMBiKY",
    "outputId": "64e02ded-02a8-4089-b892-98b8f4a1b38f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model, to_file='model.png', show_shapes=True, show_dtype=True,\n",
    "    show_layer_names=True, rankdir='TB', expand_nested=False, dpi=96\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LU4GDF_aYtfQ",
    "outputId": "81e899bd-9926-412b-ab1b-bd9c0754c19d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-03 22:19:51.145305: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-03-03 22:19:51.145339: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['Conv1_input'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 28, 28, 1)\n",
      "        name: serving_default_Conv1_input:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['Softmax'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 10)\n",
      "        name: StatefulPartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n",
      "\n",
      "Defined Functions:\n",
      "  Function Name: '__call__'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='Conv1_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='Conv1_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "\n",
      "  Function Name: '_default_save_signature'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='Conv1_input')\n",
      "\n",
      "  Function Name: 'call_and_return_all_conditional_losses'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='Conv1_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='Conv1_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir {export_path} --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "Luqm_Jyff9iR",
    "outputId": "5374fe71-261b-491a-de13-573c15be43fc",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show(idx, title):\n",
    "  plt.figure()\n",
    "  plt.imshow(test_images[idx].reshape(28,28))\n",
    "  plt.axis('off')\n",
    "  plt.title('\\n\\n{}'.format(title), fontdict={'size': 16})\n",
    "\n",
    "import random\n",
    "rando = random.randint(0,len(test_images)-1)\n",
    "show(rando, 'An Example Image: {}'.format(class_names[test_labels[rando]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2dsD7KQG1m-R"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('request.json', 'w') as f:\n",
    "    json.dump({\"signature_name\": \"serving_default\", \"instances\": test_images[0:3].tolist()}, f)\n",
    "\n",
    "#data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": test_images[0:3].tolist()})\n",
    "#print('Data: {} ... {}'.format(data[:50], data[len(data)-52:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "vGvFyuIzW6n6"
   },
   "outputs": [],
   "source": [
    "#!pip install -q requests\n",
    "\n",
    "#import requests\n",
    "#headers = {\"content-type\": \"application/json\"}\n",
    "#json_response = requests.post('http://localhost:8501/v1/models/Fashion:predict', data=data, headers=headers)\n",
    "#predictions = json.loads(json_response.text)['predictions']\n",
    "\n",
    "#show(0, 'The model thought this was a {} (class {}), and it was actually a {} (class {})'.format(\n",
    "#  class_names[np.argmax(predictions[0])], np.argmax(predictions[0]), class_names[test_labels[0]], test_labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zRftRxeR1tZx"
   },
   "outputs": [],
   "source": [
    "#### Same as above but specifies API version number\n",
    "\n",
    "#headers = {\"content-type\": \"application/json\"}\n",
    "#json_response = requests.post('http://localhost:8501/v1/models/fashion_model/versions/1:predict', data=data, headers=headers)\n",
    "#predictions = json.loads(json_response.text)['predictions']\n",
    "\n",
    "#for i in range(0,3):\n",
    "#  show(i, 'The model thought this was a {} (class {}), and it was actually a {} (class {})'.format(\n",
    "#    class_names[np.argmax(predictions[i])], np.argmax(predictions[i]), class_names[test_labels[i]], test_labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8eQhoFkZHWlX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "REST_simple.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
